\documentclass[svgnames]{report}
\usepackage[utf8]{inputenc} 
\usepackage{polski}       
\usepackage{a4wide}
\usepackage{graphicx}
\usepackage{amsmath,amssymb}
\usepackage{bbm}            % sudo apt-get install texlive-fonts-recommended texlive-fonts-extra
\usepackage{amsthm}
\usepackage{algorithmic}	% sudo apt-get install texlive-science
\usepackage{listings}             % Include the listings-package
\usepackage{framed}

\makeatletter
 \renewcommand\@seccntformat[1]{\csname  the#1\endcsname.\quad}
 
 
\begin{document}
\tableofcontents
\chapter{Zagadnienia}
[TODO: trzeba podzielić na części egzaminu]
\begin{itemize}

\item Algorytmy
\begin{itemize}
	\item mnożenie po rosyjsku
	\item szybkie potęgowanie
	\item szybkie obliczanie liczb Fibonacciego
	\item algorytmy sortowania: select i insert
	\item maszyna RAM jako model obliczeń
	\item notacja asymptotyczna
\end{itemize}

\item Algorytmy zachłanne
\begin{itemize}
	\item problem wydawania reszty
	\item algorytmy znajdowania minimalnego drzewa rozpinającego
	\begin{itemize}
		\item algorytm Prima
		\item algorytm Kruskala
		\item algorytm Boruvki
	\end{itemize}
	\item szeregowanie zadań
	\item szeregowanie zadań z deadlineami
\end{itemize}

\item Metoda Dziel i Zwyciężaj
\begin{itemize}
	\item algorytmy sortowania (mergesort, quick sort)
	\item algorytmy mnożenia długich liczb (Karatsuby)
\end{itemize}

\item Metoda Dziel i Zwyciężaj (cd)
\begin{itemize}
	\item algorytmy mnożenia długich liczb oparte na podziale na wiele części
	\item jednoczesne znajdowanie maksimum i minimum
	\item sieć permutacyjna Waksmana-Benesa
	\item znajdowanie najbliższej pary punktów na płaszczyźnie
	\item zachłanny algorytm aproksymacyjny dla problemu Set Cover
\end{itemize}

\item Programowanie dynamiczne
\begin{itemize}
	\item obliczanie współczynnika dwumianowego
	\item stokrotki
	\item znajdowanie nakrótszych dróg w grafie między wszystkimi parami wierzchołków
	\item algorytm Floyda Warshalla
	\item najdłuższy wspólny podciąg
\end{itemize}

\item Programowanie dynamiczne (cd)
\begin{itemize}
	\item optymalna kolejność mnożenia macierzy
	\item przynależność słowa do języka bezkontekstowego
	\item drzewa rozpinające drabin
\end{itemize}

\item Dolne granice (cd)
\begin{itemize}
	\item gra z adwersarzem - jednoczesne znajdowanie minimum i maksimum
	\item kopiec
	\begin{itemize}
		\item definicja
		\item implementacja tablicowa
		\item realizacja operacji kopcowych
		\item zastosowania: heapsort, kolejka priorytetowa
	\end{itemize}
	
	\item metody dowodzenia dolnych granic
	\begin{itemize}
		\item argumentacja teorio-informatyczna
		\begin{itemize}
			\item drzewa decyzjne - sortowanie; dolna granica w najgorszym i średnim przypadku
			\item liniowe drzewa decyzyjne - problem: niepowtarzalność elementów
		\end{itemize}
		\item redukcje 
		\begin{itemize}
			\item nieaproksymowalność problemu komiwojażera
		\end{itemize}
	\end{itemize}
\end{itemize}


\item Kopiec (cd)
\begin{itemize}
	\item kopiec minmax
	\item Qucksort
	\item metody wyboru pivota (deterministycza, losowa, mediana z małej próbki)
	\item analiza oczekiwanego czasu działania przy losowym pivocie
	\item usprawnienia Quicksorta
	\begin{itemize}
		\item trójpodział
		\item eliminacja rekursji
		\item quicksort w miejscu
	\end{itemize}
\end{itemize}

\item Sortowanie
\begin{itemize}
	\item przez zliczanie
	\item kubełkowe
	\item leksykograficzne ciągów jednakowej długości
\end{itemize}

\item Quicksort
\begin{itemize}
	\item prostsza metoda analizy oczekiwanego czasu działania Quicksorta przy losowym wyborze pivota
\end{itemize}

\item Selekcja
\begin{itemize}
	\item znajdowanie drugiego co do wielkości elementu
	\item metoda Hoare'a
	\item metoda magicznych piątek
\end{itemize}

\item Słowniki
\begin{itemize}
	\item drzewa zrównoważone
	\begin{itemize}
		\item drzewa AVL (definicja, realizacja operacji słownikowych)
		\item drzewa czerwono-czarne (definicja, realizacja operacji słownikowych)
	\end{itemize}
	\item selekcja
	\begin{itemize}
		\item zrandomizowany algorytm oparty na próbkowaniu
	\end{itemize}
	\item sortowanie ciągów niekoniecznie jednakowej długości z zastosowaniem do sprwadzania izomorfizmu drzew
\end{itemize}

\item Hashowanie
\begin{itemize}
	\item przykłady funkcji hashujących
	\item kolizje
	\item pamiętanie elementów kolidujących (nawlekanie, adresowanie otwarte)
	\item struktury samoorganizujące się
	\begin{itemize}
		\item idea
		\item heurystyki dla list samoorganizujących się
		\item drzewa rozchylane (splay)
		\item analiza zamortyzowania ciągów operacji splay
	\end{itemize}
	\item kopce dwumianowe (wersja leniwa)
	\begin{itemize}
		\item analiza zamortyzowana kosztu operacji
	\end{itemize}
	\item kopce Fibonacciego
	\begin{itemize}
		\item zastosowanie: algorytm Dijkstry
		\item wpływ kaskadowego odcięcia drzew na koszt operacji
	\end{itemize}
	\item B-drzewa
	\begin{itemize}
		\item definicja
		\item liczba operacji i/o jako miara złożoności
		\item realizacja operacji słownikowych
	\end{itemize}
	\item 2-3-drzewa i ich związek z drzewami czerwono czarnymi
	\item złączalne kolejki priorytetowe
	\begin{itemize}
		\item kopce dwumianowe (wersja gorliwa)
	\end{itemize}
\end{itemize}

\item Hashowanie (cd)
\begin{itemize}
	\item usuwanie kolizji w otwartym adresowaniu
	\begin{itemize}
		\item metoda liniowa
		\item metoda kwadratowa
		\item podwójne hashowanie
	\end{itemize}
	\item oczekiwana liczba prób przy poszukiwaniu elementu
	\item uniwersalne rodziny funkcji hashujących
\end{itemize}

\item Słowniki statyczne
\begin{itemize}
	\item optymalne drzewa BST
	\item statyczny słownik Fredman, Komlosa, Szemeredi'ego
\end{itemize}

\item{Drzewce}
\begin{itemize}
	\item definicja
	\item istnienie
	\item realizacja operacji słownikowych
\end{itemize}


\item Statyczny słownik Fredman, Komlosa, Szemeredi'ego (cd)
\begin{itemize}
	\item idea konstrukcji
	\item istnienie odpowiednich funkcji hashujących
	\item znajdowanie takich funkcji
\end{itemize}


\end{itemize}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% POCZĄTEK: pierwszy termin 2010
\chapter{I termin 2010}
\section{zadanie 1}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% POCZĄTEK: poprawka 2010

\chapter{II termin 2010}

\section{zadanie 1}
\begin{framed}
Rozwiąż poniższe równanie:
\begin{equation*}
T(n) = 
	\begin{cases}
		c 					&	\hbox{jeśli n = 1}		\\
		2 \cdot T(n-1) + 1 	&	\hbox{jeśli $n > 1$}	\\
	\end{cases}
\end{equation*}
Czy funkcja $T(n)$ jest $O(n^{log_2 n})$?

\end{framed}

Rozwiązanie równania rekurencyjnego:
\begin{eqnarray*}
T(n) 	&=& 2 \cdot T(n-1) + 1	\\
		&=&	2 \cdot ( 2\cdot T(n-2) + 1 ) + 1	\\
		&=& 2^2 \cdot T(n-2) + 2 + 1	\\
		&=&	2^3 \cdot T(n-3) + 2^2 + 2 + 1 \\
		&...&	\\
		&=&	2^n\cdot T(1) + 2^{n-1} + ... + 2^2 + 2 + 1 \\
		&=& 2^n \cdot c + 2^n - 1	\\
\end{eqnarray*}
Pokażemy że $T(n) \not\in O(n^{log_2 n})$:

Z powyżej rozwiązanej rekurencji widać że: $T(n) \in \Omega (2^n)$, 
\begin{equation}
	\exists_{n_0 \in N} \forall_{n > n_0} n^{log_2 n} = \left(2^{log_2 n}\right)^{log_2 n} = 2^{(log_2 n)^2} < 2^n
\end{equation}
Wynika z tego, że $n^{log_2 n}$ nie jest ograniczeniem górnym.

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

\section{zadanie 2}
\begin{framed}
Wyznacz z dokładność do $\Theta$ (przy jednorotnym kryterium) poniższego fragmentu algorytmu:
\begin{algorithmic}
\STATE $suma \leftarrow 0$
\FOR {$i \leftarrow 1 \ to \ n \ \do$}
	\STATE $k \leftarrow 1$
	\WHILE {$k \leqslant i$}
		\STATE read(x)
		\STATE $suma \leftarrow suma + x \cdot k$
		\STATE $k \leftarrow k + k$
	\ENDWHILE
\ENDFOR
\end{algorithmic}
\end{framed}

\begin{equation*}
	\sum\limits_{i=0}^{n} log_2 i = log_2 1 + ... + log_2 n = log_2(1 \cdot ... \cdot n) = log_2(n!)
\end{equation*}
Algorytm jest $\Theta(log_2(n!))$

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

\section{zadanie 3}
\begin{framed}
Załóżmy, że w definicji drzewa czerwno-czarnego zmienimy warunek mówiący iż dzieci czerwonego ojca są czarne na warunek:

dzieci czerwonego ojca, którego ojciec też jest czerwony są czarne

Określ jak zmieni się (z dokładnością) do stałego czynnika maksymalna wysokość tak zdefiniowanych drzew?

\end{framed}

Przy orginalnym założeniu:
\begin{equation*}
h \leqslant 2 \cdot log(n-1)
\end{equation*}
Po zamianie założeniam, minimalna liczba czarnych wierzchołków w każdej scieżce od korzenia do liścia, zmieniła się z $\frac{h}{2}$ na $\frac{h}{3}$. Warunek na h przyjmuje teraz postać:
\begin{equation*}
h \leqslant 3 \cdot log(n-1)
\end{equation*}

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

\section{zadanie 4}
\begin{framed}
Z ilu drzew może składać sie kopiec dwumianowy (wersja eager) zawierający 49 elementów?
\end{framed}
Ponieważ jest to kopiec typu eager nie może miec dwóch drzew dwumianowych tego samego stopnia.
Aby przekonać się z ilu drzew dwumianowych się on składa, zamieńmy liczbę jego elementów na liczbe o binarną.
\begin{equation}
49_{10} = 32_{10} + 16_{10} + 1_{10} = 2_{10}^5 + 2_{10}^4 + 2_{10}^0 = 110001_2
\end{equation} 
Widźimy, że kopiec ten składa się z trzech drzew: $B_5$ , $B_4$ i $B_1$.

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

\section{zadanie 5}
\begin{framed}
Dla której z poniżej podanych struktur danych koszt (najgorszego przypadku) wykonania operacji $find(i)$ sprawdzającej czy klucz $i$ jest pamiętany w struktrze jest $O(log n)$, gdzie $n$ jest rozmiarem struktury?
\begin{description}
	\item[(a)] drzewo binarnych przeszukiwań,
	\item[(b)] drzewo AVL
	\item[(c)] kopiec
	\item[(d)] kopiec dwumianowy
	\item[(e)] kopiec Fibonacciego
	\item[(f)] drzewo czerwono-czarne
\end{description}
\end{framed}
Dla struktur b, f koszt wykonania operacji $find(i)$ jest $O(log n)$.
Dla pozostałych jest on $O(n)$.

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

\section{zadanie 6}
\begin{framed}
Podaj przykłady nietrywialnych zastosowań poniższych algorytmow i struktur danych:
kopiec, kopiec Fibonacciego, kopiec dwumianowy, sortowanie leksykograficzne ciągów róznej dlugości
\end{framed}

\begin{tabular}{l|l}
					&	Przykład zastosowania	\\	\hline
kopiec 				&	algorytm sortowanie przez kopcowanie	\\	\hline
kopiec Fibonacciego &	algorytm Dijskry	\\	\hline
kopiec dwumianowy 	&	kolejka priorytetowa	\\	\hline
sortowanie leksykograficzne ciągów różnej długości & algorytm rozpoznający czy dwa drzewa są izomorficzne	\\	\hline
\end{tabular}

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

\section{zadanie 14}
\begin{framed}
W problemie LCS stosowaliśmy redukcję problemu porównując ostatnie litery X i Y. Czy jakies znaczenie ma fakt, że są to ostatnie litery a nie pierwsze?
\end{framed}
Nie jest to istotne.

Weźmy sobie ciągi $X$, $Y$ i niech algorytm $LCS(X, Y)$, obliczający długość najdłuższego podciągu, wykorzystując redukcję problemu porównując ostatnie litery ciagów.
Zaóważmy że algorytm $LCS'(X, Y) = LCS(X^R, Y^R)$ również poprawnie oblicza długośc najdłuższego podciągu ciagów X, Y, ale można powiedzieć że wykorzystuje on redukcję problemu porównując pierwsze litery X, Y.

%% KONIEC: poprawka 2010
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{thebibliography}{99}
\bibitem{Test} test reference
\end{thebibliography}
\end{document}



